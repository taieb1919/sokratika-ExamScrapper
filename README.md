# DNB Annales Scraper ğŸ“š

Un outil Python simple et efficace pour scraper et tÃ©lÃ©charger les annales du DiplÃ´me National du Brevet (DNB) depuis le site officiel du ministÃ¨re de l'Ã‰ducation nationale franÃ§ais.

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## ğŸ¯ FonctionnalitÃ©s

- âœ… **Scraping avec Selenium** - Navigation automatique dans les pages avec JavaScript
- âœ… **Pagination automatique** - Parcourt toutes les pages
- âœ… **Extraction de liens** `/document/*/download` avec mÃ©tadonnÃ©es
- âœ… **TÃ©lÃ©chargement concurrent** avec gestion de threads
- âœ… **Organisation automatique** par annÃ©e et matiÃ¨re
- âœ… **Extraction automatique des ZIP** - DÃ©compression immÃ©diate aprÃ¨s tÃ©lÃ©chargement
- âœ… **Support multi-format** - PDF, ZIP, DOC, DOCX, ODT, etc.
- âœ… **Gestion d'erreurs robuste** avec retry automatique
- âœ… **Rate limiting** pour respecter le serveur
- âœ… **Logging complet** avec rotation de fichiers et log d'erreurs sÃ©parÃ©
- âœ… **Interface CLI** intuitive
- âœ… **Mode headless** ou visible pour le debugging

## ğŸ“‹ PrÃ©requis

- Python 3.8 ou supÃ©rieur
- pip (gestionnaire de paquets Python)
- **Google Chrome** (navigateur)
- Connexion Internet

### Installation de ChromeDriver

ChromeDriver est gÃ©rÃ© automatiquement par Selenium 4.15+. Assurez-vous simplement que Google Chrome est installÃ©.

## ğŸš€ Installation

### 1. Cloner le dÃ©pÃ´t

```bash
git clone https://github.com/taieb1919/sokratika-ExamScrapper.git
cd sokratika-ExamScrapper
```

### 2. CrÃ©er un environnement virtuel (recommandÃ©)

**Windows:**

```bash
python -m venv venv
venv\Scripts\activate
```

**Linux/Mac:**

```bash
python -m venv venv
source venv/bin/activate
```

### 3. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

## ğŸ“– Utilisation

### Interface en ligne de commande (CLI)

Le projet fournit une interface CLI unifiÃ©e avec des options flexibles :

#### Utilisation de base

```bash
# Scraper et afficher le rÃ©sumÃ© (par dÃ©faut)
python main.py

# Limiter le nombre de pages parcourues (ex: 2 premiÃ¨res pages)
python main.py --pages 2
```

#### Validation des donnÃ©es

```bash
# Valider les entrÃ©es et gÃ©nÃ©rer validation_report.csv
python main.py --validate

# Valider en limitant Ã  2 pages
python main.py --validate --pages 2
```

#### TÃ©lÃ©chargement des PDFs

```bash
# TÃ©lÃ©charger tous les PDFs aprÃ¨s scraping
python main.py --download

# TÃ©lÃ©charger en limitant Ã  2 pages
python main.py --download --pages 2

# Valider d'abord, puis tÃ©lÃ©charger seulement si validation OK
python main.py --validate --download
```

#### Options avancÃ©es

```bash
# Changer le niveau de logging
python main.py --log-level DEBUG --download

# SpÃ©cifier un fichier de log personnalisÃ©
python main.py --log-file custom.log --download
```

### Utilisation programmatique

```python
from src.scraper import DNBScraper
from src.downloader import FileDownloader

# Scraping
scraper = DNBScraper()
scraper.extract_pdf_links()
entries = scraper.structured_entries

# TÃ©lÃ©chargement
downloader = FileDownloader()
urls = [f.download_url for entry in entries for f in entry.files]
results = downloader.batch_download(urls=urls)

print(f"TÃ©lÃ©chargÃ©s: {len(results['successful'])}")
print(f"Ã‰checs: {len(results['failed'])}")
```

## ğŸ—‚ï¸ Structure du projet

```
sokratika-ExamScrapper/
â”‚
â”œâ”€â”€ src/                        # Code source principal
â”‚   â”œâ”€â”€ __init__.py            # Initialisation du package
â”‚   â”œâ”€â”€ scraper.py             # Module de scraping (DNBScraper)
â”‚   â”œâ”€â”€ downloader.py          # Module de tÃ©lÃ©chargement (PDFDownloader)
â”‚   â”œâ”€â”€ parser.py              # Analyseur de mÃ©tadonnÃ©es (MetadataParser)
â”‚   â””â”€â”€ utils.py               # Fonctions utilitaires
â”‚
â”œâ”€â”€ config/                    # Configuration
â”‚   â””â”€â”€ settings.py            # ParamÃ¨tres de configuration
â”‚
â”œâ”€â”€ data/                      # DonnÃ©es tÃ©lÃ©chargÃ©es
â”‚   â”œâ”€â”€ raw/                   # Fichiers tÃ©lÃ©chargÃ©s (organisÃ©s par annÃ©e/matiÃ¨re)
â”‚   â”‚   â”œâ”€â”€ 2024/              # Organisation par annÃ©e
â”‚   â”‚   â”‚   â”œâ”€â”€ FranÃ§ais/      # Organisation par matiÃ¨re
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ fichier.pdf
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ archive.zip
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ archive/   # Dossier extrait automatiquement
â”‚   â”‚   â”‚   â””â”€â”€ MathÃ©matiques/
â”‚   â”‚   â””â”€â”€ 2023/
â”‚   â””â”€â”€ metadata/              # Fichiers JSON avec mÃ©tadonnÃ©es
â”‚
â”œâ”€â”€ logs/                      # Fichiers de logs
â”‚   â”œâ”€â”€ dnb_scraper_YYYY-MM-DD.log  # Log complet avec rotation
â”‚   â””â”€â”€ errors_only.log             # Log des erreurs uniquement
â”‚
â”‚
â”œâ”€â”€ main.py                    # Point d'entrÃ©e CLI
â”œâ”€â”€ requirements.txt           # DÃ©pendances Python
â”œâ”€â”€ setup.py                   # Configuration du package
â””â”€â”€ README.md                  # Ce fichier
```

## ğŸ“Š MÃ©tadonnÃ©es extraites

Le scraper extrait automatiquement :

- **AnnÃ©e** : Depuis le nom de fichier (ex: "24" â†’ "2024")
- **MatiÃ¨re** : FranÃ§ais, MathÃ©matiques, Histoire-GÃ©ographie, etc.
- **Session** : normale, remplacement
- **SÃ©rie** : gÃ©nÃ©rale, professionnelle
- **Type de document** : sujet ou correction

## âš™ï¸ Configuration

### Variables d'environnement (optionnel)

CrÃ©ez un fichier `.env` pour personnaliser :

```env
# Principales options
SELENIUM_HEADLESS=True         # Mode headless
MAX_WORKERS=5                  # TÃ©lÃ©chargements concurrents
LOG_LEVEL=INFO                 # Niveau de log
```

## ğŸ“ Organisation des fichiers

Les fichiers tÃ©lÃ©chargÃ©s sont automatiquement organisÃ©s :

```
data/raw/
â”œâ”€â”€ 2024/
â”‚   â”œâ”€â”€ FranÃ§ais/
â”‚   â”‚   â”œâ”€â”€ 24genfrdag1_v11.pdf
â”‚   â”‚   â”œâ”€â”€ 24genfrdag1_corrige.pdf
â”‚   â”‚   â”œâ”€â”€ archive_documents.zip
â”‚   â”‚   â””â”€â”€ archive_documents/     # Dossier extrait automatiquement
â”‚   â”‚       â”œâ”€â”€ document1.pdf
â”‚   â”‚       â””â”€â”€ document2.pdf
â”‚   â”œâ”€â”€ MathÃ©matiques/
â”‚   â”‚   â”œâ”€â”€ 24genmathag1_v11.pdf
â”‚   â”‚   â””â”€â”€ 24genmathag1_corrige.pdf
â”‚   â””â”€â”€ Histoire-GÃ©ographie/
â”‚       â””â”€â”€ 24genhisgeoag1_v11.pdf
â””â”€â”€ 2023/
    â””â”€â”€ ...
```

**Note** : Les fichiers ZIP sont automatiquement extraits dans un dossier du mÃªme nom (sans l'extension `.zip`). Le fichier ZIP original est conservÃ©.

## ğŸ›¡ï¸ Bonnes pratiques

- **Respect du serveur** : Rate limiting, retry automatique
- **Logging complet** : Logs avec rotation + log d'erreurs sÃ©parÃ© (`errors_only.log`)
- **Code qualitÃ©** : Type hints, docstrings, gestion d'erreurs

## ğŸ”§ API

```python
# Scraper
scraper = DNBScraper()
scraper.extract_pdf_links()
entries = scraper.structured_entries

# TÃ©lÃ©chargeur
downloader = FileDownloader()
downloader.batch_download(urls)
```

## ğŸ› DÃ©pannage

### ChromeDriver not found

```bash
# Selenium 4.15+ gÃ¨re ChromeDriver automatiquement
# VÃ©rifiez que Chrome est installÃ©
```

### Erreur de connexion

```bash
# VÃ©rifier la connectivitÃ©
python -c "import requests; print(requests.get('https://eduscol.education.fr').status_code)"
```

### ImportError

```bash
# RÃ©installer les dÃ©pendances
pip install --force-reinstall -r requirements.txt
```

## ğŸ“ Exemples

### Obtenir des statistiques

```python
from src.scraper import DNBScraper

scraper = DNBScraper()
scraper.extract_pdf_links()
stats = scraper.get_summary_dict()

print(f"Total: {stats['total']}")
print(f"AnnÃ©es: {stats['years']}")
print(f"MatiÃ¨res: {stats['subjects']}")
```

### TÃ©lÃ©charger uniquement 2024

```python
from src.scraper import DNBScraper
from src.downloader import FileDownloader

scraper = DNBScraper()
scraper.extract_pdf_links()

# Filtrer 2024
entries_2024 = [e for e in scraper.structured_entries
                if e.session.value.startswith('2024')]

urls_2024 = [f.download_url for entry in entries_2024 for f in entry.files]

downloader = FileDownloader()
results = downloader.batch_download(urls=urls_2024)
```

## âš–ï¸ Licence

MIT License - Voir le fichier `LICENSE` pour plus de dÃ©tails.

## âš ï¸ Disclaimer

Ce projet est destinÃ© Ã  un usage Ã©ducatif et respecte les conditions d'utilisation du site eduscol.education.fr.
